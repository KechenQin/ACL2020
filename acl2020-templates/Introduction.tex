\begin{figure}[t]
 \centering
 \includegraphics[width=1\linewidth]{figs/fig1.png}
 \caption{One QA example with Multiple Relation Paths from \textsc{ComplexWebQuestion}-1.1. The blue color highlighted is the extracted topic entity. Each square represents an entity, and the arrows represent the relations. Relation path $R_1$ to $R_4$ are the good ones containing meaningful relation paths to the final answer. $R_5$ and $R_6$ are the worse paths that generate a larger final answer set containing some wrong entities. $R_7$ is the worst one as its relation path is totally not interpretable and the answer set is huge.}
 \label{QAPaths}
\end{figure}

\section{Introduction}

Knowledge-based question answering (KBQA) is the task of finding answers to questions by processing a structured knowledge base $\mathcal{KB}$. %where the beliefs are stored as triples containing two entities and the relation linking them. 
A $\mathcal{KB}$ consists of a set of entities $\mathcal{E}$, a set of relations $\mathcal{R}$, and a set of literals $\mathcal{S}$. A knowledge base fact is defined as $(h,r,t)$, where $h\in \mathcal{E}$ is the head entity, $t \in \mathcal{E} \bigcup \mathcal{S}$ is the tail entity/literal, and $r\in \mathcal{R}$ is the directed relation between $h$ and $t$. To answer a simple single-relation question (\emph{i.e.} a 1-hop question) like: ``Who is the president of the United States?'', %a KBQA system first identifies the topic/focus entity (\emph{i.e.} United States) and the relation (\emph{i.e.} ``president '') asked in the question, then searches for the entity by matching the entity-relation tuple $\textless$United States, president, $?\textgreater$ over KB. \kalpa{use of a topic entity is approach specific. Many KBQA systems exist that do not use topic entity. E.g., template based QA}
a typical KBQA system first identifies the entity (\emph{i.e.} United States) and the relation (\emph{i.e.} ``president'') asked in the question, and then searches for the answer entity by matching the entity-relation tuple $\textless$United States, president, $?\textgreater$ over $\mathcal{KB}$.


While the single-hop question can be answered by searching a predicate relation in $\mathcal{KB}$, it is not trivial to answer more complex multi-hop questions containing multiple entities and relations with constraints. Take two types of multi-hop questions for example: (1) For a complex compositional question, it is not trivial to extract the correct relations in their right sequences together with the correct head and tail entities, and (2) For a complex conjunction question, it is difficult to extract multiple reasoning paths, and combine their results at the end. 

Most prior work on multi-hop KBQA focuses on improving model architecture to better fit each given question to the most optimal relation path, which is given as its ground truth, and accordingly predict the most possible reasoning path during prediction. In reality, however, it is always possible that there exists many other relation paths leading to the answer, which are not given as ground truth. %It is hard to pre-define the maximum number of hops in a complex question because different questions may need different number of hops to reach their answers.
%\kechen{list a few problems (1) it hard to control number of hops. (2) how to decompose a complex question into sub-question. (3) ...} 
%\kechen{add something to explain why the above two points lead to decomposing into two sub-tasks?}
 %with random walks \cite{DBLP:conf/emnlp/GardnerTKM13} or is formulated as a Markov decision process (MDP) based reinforcement learning problem~\cite{DBLP:conf/emnlp/XiongHW17}.
%\kechen{Most of the existing KBQA systems cannot handle these two issues simultaneously. People have to pre-define different rules to solve different type of complex querys. For example, list a few work using different pre-defined strategy to solve complex QA.}%1. use different model to train, 2. neural program
%traditional approaches consider all the paths and search for the best path among them, where their searching algorithms either leverage path-ranking algorithms with random walks \cite{DBLP:conf/emnlp/GardnerTKM13} or is formulated as a Markov decision process (MDP) based reinforcement learning problem~\cite{DBLP:conf/emnlp/XiongHW17}. Since the complexity of the searching process can grow exponentially when the number of hops increase, some recent researches add decision markers or a terminal relation to decide whether a searching path should terminate or continue, in order to reduce the searching space and complexity \cite{DBLP:conf/naacl/ChenCCNK19}.
%It is commonly observed that, by using the above mentioned algorithms, the extracted relation path may not always be the best one or even can be a wrong one. The main reason is because during training, for one question, their models are trying to learn and fit to only one possible relation path, which is given as its ground truth. \kechen{while during prediction only predict one path}In reality, however, it is always possible that there exists many other relation paths leading to the answer, which are not given as ground truth. 
As the example given in Figure \ref{QAPaths}, for the question \textit{``What city is home to the University that is known for Purdue Boilermakers men's basketball?''}, there are 7 relation paths $R_n={e^n_0\rightarrow r^n_1 \rightarrow e^n_1 \rightarrow \cdots \rightarrow e^n_{ans}}\ (n=\lbrace 1, \dots, 7 \rbrace)$%\footnote{An exchangeable way to define relation path is omitting entities in the definition, because entity is determined by given the topic entity, relations, and the knowledge base. For simplicity, we simplify this relation path definition as a list of sequential relations $(r_{1}^n, r_{2}^n, \cdots, r_{T}^n)$ in the following part of this paper.}
, leading to an answer set containing the ground truth entity ``West Lafayette'', but only R1 is labeled as the ground truth relation path in the dataset. It is unlikely for the model to infer all possible relation paths that can direct the model to the answer set containing the final answer, only based on one given training path. It is not even possible for the model to differentiate the good paths from the bad ones, which are some unreasonable paths also leading to the answer sets %containing our target answer
or some reasonable paths leading to a large predicted set which contains both correct answer and noisy results. As the example given in Figure \ref{QAPaths}, relation paths $R_1$ to $R_4$ are the good ones containing meaningful relation paths to the final answer, by executing different number of hops. Comparatively, relation paths $R_5$ and $R_6$ generate a larger final answer set containing not only the correct answer but also many other wrong entities. These paths can be treated as inferior to the top 4 paths, since they give some extra invalid answers besides the correct one. In the example, path $R_7$ is even worse as its relation path is totally not interpretable plus the final answer set is exaggeratedly large which mainly contains invalid answers, hence should not be considered as a positive relation path training sample for this question. 

%Although someone may claim that we can use multiple relation paths as ground truths for one question to improve the coverage and performance, it is still not feasible to label all valid relation paths considering the complexity of ground truth label preparation. 
%\kechen{combine this paragraph with the next paragraph? now we have two separate paragraphs to first introduce the issue and then use an example to explain it. should we combine them together?}

In this paper, we propose an end-to-end multi-hop KBQA system, which successfully leverage the training information from multiple relation paths, and learn the good relation paths over the inferior or the bad ones, by being given the labels of only one valid relation path (as in most KBQA datasets) or even no relation labels. We model the relation paths as a latent variable, and propose supporting training and prediction methods. Experimental results show that the system can output diverse relation paths, and reward the ``better'' paths over the inferior ones by assigning ``better'' paths higher probabilities. Our method can be applied to most KBQA systems to predict entity and relation, and can be used with any model architecture. We achieve state-of-the-art performance on three popular KBQA datasets for single-hop and multi-hop questions.%taking the size of their answer set into consideration, \emph{i.e.} the larger is the final answer set, the worse is a relation path, as it contains more irrelevant answer information. \kechen{modify the last sentence} %We also use a sampling approach to filter the wrong paths like $R_8$ in our example. 
% Specifically, we make the following contributions:\\
% 1. We introduce a novel multi-hop KBQA structure, which can predict the relation sequence of any length without pre-defining the number of maximum hops and generate final answers at the last hop.\\
% 2. We design a novel loss function using latent variables, such that the system can be trained without being given any ground truth relation path, or by leveraging more valid training paths information even if one ground truth path is given. We also give detailed analysis to demonstrate the benefits of using the new loss function.\\
% 3. We achieve state-of-the-art performance on three popular KBQA dataset containing single-hop and multi-hop questions.
%Specifically, we make the following contributions:
%\begin{enumerate}
%    \item We introduce a novel multi-hop KBQA system, which can leverage the information from multiple relation paths. %predict the relation sequence of any length without pre-defining the number of maximum hops and generate final answers at the last hop.
%    \item We design a novel loss function and the corresponding training and prediction methods. Detailed analysis is given to demonstrate the benefits of using this new loss function.
%    \item We achieve state-of-the-art performance on three popular KBQA datasets for single-hop and multi-hop questions.
%\end{enumerate}
