%\subsection{Knowledge based Question Answering (KB-QA)}
\section{Related Work}
%Most of the early KB-QA models are designed for QA problems that can be answered by a single hop, where one hop is defined as the traversal from one entity to another via a single relation. 

Most of the existing multi-hop KBQA systems %\cite{DBLP:conf/acl/YuYHSXZ17,DBLP:journals/corr/abs-1801-09893,DBLP:conf/coling/ZhouHZ18,DBLP:conf/naacl/ChenCCNK19} 
approach this task by decomposing it into two sub-tasks:
%Currently, there are mainly two main categories of methods to tackle the complex KBQA problems, the first category is based on semantic parsing, and the other category mainly relies on the embeddings (XXX) for information retrieval (IR). %Their differences will be discussed further in the relation work section, and i
%In this paper, we focus on the second category, \emph{i.e.} the embedding based approach, which can either predict the answer directly (XXX) or search (a) relation path(s) leading to the final answer entity (XXX). Conventionally, the relation path searching algorithm consists two main subtasks
topic--entity linking and relation extraction. The topic--entity linking gives the system an entry point to start searching, and the relation extraction is used to search relation paths leading to the final answer. %Unlike the simple single relation questions, for complex questions, the path to the final answer may contains multiple hops, where one hop is defined as a searching step between one entity to another via a single relation. 
%For entity linking, there exists many off-the-shell tools  \cite{DBLP:journals/corr/YangC16a} that can give decent performance, and most of the current KBQA models rely on them. For relation extraction, traditional approaches consider all the paths as candidates and search for the best one among them using ranking algorithms. 
%Following this track, existing multi-hop KBQA approaches can be categorized into three groups. 
Following this track, a straightforward idea is to match the question to a candidate entity/relation directly via calculating the similarity between them \cite{DBLP:journals/corr/abs-1801-09893,DBLP:conf/adbis/YuHYZW18,DBLP:conf/ijcai/LanW019}. This method is not very suitable for multi-hop questions with long paths, because the number of candidate entity-relation combinations grows exponentially as the number of hops increases. To tackle this issue, people propose to decompose the input question into several single-hop questions, and use the existing method to solve each simple question. The decomposition methods are based on semantic parsing \cite{DBLP:conf/www/AbujabalYRW17,DBLP:conf/emnlp/LuoLLZ18} or templates \cite{DBLP:journals/corr/abs-1908-11053}. A similar idea is to encode the reasoning information hop by hop, and predict the final answer at the last hop \cite{DBLP:conf/emnlp/MillerFDKBW16,DBLP:conf/coling/ZhouHZ18,DBLP:conf/naacl/ChenCCNK19}. %which is a group of methods that are more capable of handling multi-hop questions. 
%\newcite{DBLP:conf/acl/LiYSLYCZL19} casts the task as a multi-turn question answering problem, where the extraction of entities and relations is transformed to the task of identifying answers of template questions. 
%It is also popular to enhance ERL results by using multi-task learning with the help of additional annotations \cite{DBLP:conf/aaai/DengXLYDFLS19,DBLP:conf/ijcai/ShaoGBJCLD19}. 

Another line of work has looked at solving KBQA task with only final answer as supervision. \newcite{DBLP:conf/acl/LiangBLFL17} first propose to cast KBQA as a program generation task using neural program induction (NPI) techniques. They learn to translate the query to a program like logical form executable on the KB. As a follow up, \newcite{DBLP:conf/ijcai/AnsariSKBSC19} improves this idea by incorporating high level program structures. Both these NPI models do not require annotated relation path as supervision, but they need some prior knowledge to design the program templates. In other work, \newcite{DBLP:journals/corr/abs-1909-04849} recently propose a latent variable approach which is similar to the one described here, but applied on text-based QA scenarios. The main difference between our work is that our method aims at finding multiple reasoning paths directing to the answer, while their method only focuses on extracting single optimal solution. We employ inference during training to filter our irrelevant paths, while they use it to identify the optimal solution.